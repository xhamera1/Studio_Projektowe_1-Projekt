{
 "cells": [
  {
   "cell_type": "code",
   "id": "2ca2eb17-5c89-4b02-aa19-333a40ea1fd6",
   "metadata": {},
   "source": [
    "# https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset/data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5155c9e0-79b2-400d-874b-7dcf0dc7f75c",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f103fdd2-4e02-4d1a-91a0-b94049ef995d",
   "metadata": {},
   "source": [
    "df = pd.read_csv('../data/stroke_prediction_dataset.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "228afbe6-f9a1-49bf-951f-2ec42bea59ac",
   "metadata": {},
   "source": [
    "print('Shape of dataset:', df.shape)\n",
    "print('First 15 rows:')\n",
    "display(df.head(15))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b053fefd-dbc5-4dac-86df-e96e1c12fa8d",
   "metadata": {},
   "source": [
    "df = df.drop(columns=['id'])\n",
    "print(df.info())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "24de932d-e01f-4f3e-a3aa-6e03a0c60ce9",
   "metadata": {},
   "source": [
    "print(df.isnull().sum())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0a072ac5-f815-47f7-a326-9f6be40ae054",
   "metadata": {},
   "source": [
    "# Data Preprocessing & Feature Engineering"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5599aa6b-b71f-485f-9b5c-3c9689e57598",
   "metadata": {},
   "source": [
    "# Count missing values in the problematic features\n",
    "missing_analysis = pd.DataFrame({\n",
    "    'feature': ['bmi', 'gender', 'smoking_status'],\n",
    "    'total_missing': [\n",
    "        df['bmi'].isna().sum(),\n",
    "        (df['gender'] == 'Other').sum(),\n",
    "        (df['smoking_status'] == 'Unknown').sum()\n",
    "    ],\n",
    "    'missing_percentage': [\n",
    "        (df['bmi'].isna().sum() / len(df)) * 100,\n",
    "        ((df['gender'] == 'Other').sum() / len(df)) * 100,\n",
    "        ((df['smoking_status'] == 'Unknown').sum() / len(df)) * 100\n",
    "    ]\n",
    "})\n",
    "\n",
    "print('Missing Value Analysis:')\n",
    "print(missing_analysis)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d201b91c-ceb5-4da6-8a5a-8baf08325019",
   "metadata": {},
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "def clean_stroke_data(df):\n",
    "    '''\n",
    "    Comprehensive cleaning function for Stroke dataset\n",
    "    '''\n",
    "    # Make a copy to avoid modifying original\n",
    "    df_clean = df.copy()\n",
    "    df_clean = df_clean.rename(columns={'gender': 'sex'})\n",
    "\n",
    "    # Step 1: Drop high-missing columns\n",
    "    # Dropping ever_married and Residence_type features because their clinical / practical relevance for stroke prediction is questionable\n",
    "    columns_to_drop = ['smoking_status', 'ever_married', 'Residence_type']\n",
    "    df_clean = df_clean.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "    # Step 2: Clean column names\n",
    "    df_clean.columns = df_clean.columns.str.strip()\n",
    "\n",
    "    # Step 3: Handle any minor missing values\n",
    "    df_clean = df_clean[~(df_clean['sex'] == 'Other')]\n",
    "\n",
    "    # Step 4: Convert numerical columns to proper numeric type\n",
    "    df_clean['age'] = df_clean['age'].astype(int)\n",
    "    df_clean['hypertension'] = df_clean['hypertension'].astype(int)\n",
    "    df_clean['heart_disease'] = df_clean['heart_disease'].astype(int)\n",
    "    df['avg_glucose_level'] = df['avg_glucose_level'].astype(float)\n",
    "    df['bmi'] = df['bmi'].astype(float)\n",
    "\n",
    "\n",
    "    # Step 5: Convert categorical columns (handle any remaining '?')\n",
    "    df_clean['sex'] = df_clean['sex'].map({'Male': 1, 'Female': 0})\n",
    "    wt_map = {\n",
    "        'Private':       0,\n",
    "        'Self-employed': 1,\n",
    "        'Govt_job':      2,\n",
    "        'children':      3,\n",
    "        'Never_worked':  4\n",
    "    }\n",
    "    df_clean['work_type'] = df_clean['work_type'].map(wt_map).astype(int)\n",
    "\n",
    "    # Step 6: Impute missing values using KNNImputer\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    df_clean = pd.DataFrame(imputer.fit_transform(df_clean), columns=df_clean.columns)\n",
    "\n",
    "    # Step 7: Drop rows with any remaining missing values\n",
    "    initial_rows = len(df_clean)\n",
    "    df_clean = df_clean.dropna()\n",
    "    final_rows = len(df_clean)\n",
    "\n",
    "    print(f'  Data cleaning completed:')\n",
    "    print(f'  Rows removed due to missing values: {initial_rows - final_rows}')\n",
    "    print(f'  Final dataset shape: {df_clean.shape}')\n",
    "\n",
    "    # Step 8: Create binary target\n",
    "    df_clean['stroke'] = (df_clean['stroke'] > 0).astype(int)\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "# Apply the comprehensive cleaning\n",
    "df_clean = clean_stroke_data(df)\n",
    "\n",
    "# Verify no more 'NaN' values\n",
    "print('  Verification - No more missing values:')\n",
    "\n",
    "for col in df_clean.columns:\n",
    "    if (df_clean[col].isna()).any():\n",
    "        print(f'  WARNING: Still found NaN in {col}')\n",
    "    else:\n",
    "        print(f'  {col}: Clean')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "11c73cd8-17f0-4ef4-a89d-7c1619f0fb95",
   "metadata": {},
   "source": [
    "print('Final Clean Dataset:')\n",
    "print(f'Shape: {df_clean.shape}')\n",
    "print(f'Columns: {df_clean.columns.tolist()}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5c597cb1-90d3-45b2-9b70-912be7731c60",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4bd3eff4-64ae-4dc9-95a5-493fc087315d",
   "metadata": {},
   "source": [
    "print('Target Distribution:')\n",
    "print(df_clean['stroke'].value_counts())\n",
    "print(f'Baseline accuracy: {max(df_clean['stroke'].value_counts(normalize=True)):.3f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "88c60ea7-2592-4604-bd6f-a613cb0abf21",
   "metadata": {},
   "source": [
    "# The dataset is highly imbalanced, so accuracy is misleading.\n",
    "# F1-score is used instead because it better reflects performance on the minority (stroke) class.\n",
    "\n",
    "\n",
    "# Separate features and target\n",
    "X = df_clean.drop(['stroke'], axis=1)\n",
    "y = df_clean['stroke']\n",
    "\n",
    "# Split the data\n",
    "X_train_imbalanced, X_test, y_train_imbalanced, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f' Dataset Split:')\n",
    "print(f'Training set: {X_train_imbalanced.shape}')\n",
    "print(f'Test set: {X_test.shape}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "89a088e5-d84c-4944-882a-3228eca975ea",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4be7fccc-edae-47c9-b669-f6ac12f493cb",
   "metadata": {},
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=13, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=13, class_weight='balanced'),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=13),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=13),\n",
    "    'SVM': SVC(kernel='linear', random_state=13, class_weight='balanced', probability=True),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Extra Trees': ExtraTreesClassifier(n_estimators=100, random_state=13, class_weight='balanced')\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "093dd3c1-45a0-43b3-bbbb-56f44f8c14cb",
   "metadata": {},
   "source": [
    "# Set up cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=13)\n",
    "# scoring = make_scorer(f1_score)\n",
    "scoring = 'recall'\n",
    "\n",
    "# Since the dataset is imbalanced (stroke cases are rare),\n",
    "# we can use SMOTE to oversample the minority class and improve model learning.\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create pipelines with SMOTE and scaling,\n",
    "scaling_models = ['Logistic Regression', 'SVM', 'K-Nearest Neighbors']\n",
    "model_pipelines = {}\n",
    "for name, model in models.items():\n",
    "    steps = []\n",
    "\n",
    "    # add SMOTE\n",
    "    steps.append(('smote', SMOTE()))\n",
    "\n",
    "    # add scaler for models that need it\n",
    "    if name in scaling_models:\n",
    "        steps.append(('scaler', StandardScaler()))\n",
    "\n",
    "    # add classifier\n",
    "    steps.append(('classifier', model))\n",
    "\n",
    "    pipeline = Pipeline(steps)\n",
    "    model_pipelines[name] = pipeline\n",
    "\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "cv_results = {}\n",
    "print(' Running 5-Fold Cross-Validation...')\n",
    "for name, model in model_pipelines.items():\n",
    "    try:\n",
    "        cv_scores = cross_val_score(\n",
    "            model,\n",
    "            X_train_imbalanced,\n",
    "            y_train_imbalanced,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        cv_results[name] = {\n",
    "            'mean_score': cv_scores.mean(),\n",
    "            'std': cv_scores.std(),\n",
    "            'all_scores': cv_scores\n",
    "        }\n",
    "        print(f'✅ {name:25s}: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}')\n",
    "    except Exception as e:\n",
    "        print(f' {name:25s}: Error - {str(e)}')\n",
    "        cv_results[name] = {'mean_accuracy': 0, 'std_accuracy': 0, 'all_scores': []}\n",
    "\n",
    "# Display results in sorted order\n",
    "print(' Cross-Validation Results (Sorted by Performance):')\n",
    "print('=' * 60)\n",
    "\n",
    "sorted_results = sorted(\n",
    "    cv_results.items(),\n",
    "    key=lambda x: x[1]['mean_score'],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "for name, results in sorted_results:\n",
    "    print(f'{name:25s}: {results['mean_score']:.4f} ± {results['std']:.4f}')\n",
    "\n",
    "# Identify best model\n",
    "best_model_name = sorted_results[0][0]\n",
    "best_cv_score = sorted_results[0][1]['mean_score']\n",
    "print(f' Best Model: {best_model_name} (CV recall: {best_cv_score:.4f})')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b341ca6b-78e7-4c5e-9531-8e84039bd6ba",
   "metadata": {},
   "source": [
    "# Create visualization of model performance\n",
    "plt.figure(figsize=(14, 10))\n",
    "model_names = [name for name, _ in sorted_results]\n",
    "mean_scores = [results['mean_score'] for _, results in sorted_results]\n",
    "std_scores = [results['std'] for _, results in sorted_results]\n",
    "\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(model_names)))\n",
    "bars = plt.barh(range(len(model_names)), mean_scores, xerr=std_scores,\n",
    "                alpha=0.8, color=colors, edgecolor='black', height=0.7)\n",
    "\n",
    "plt.yticks(range(len(model_names)), model_names)\n",
    "plt.xlabel('Recall Score', fontsize=12)\n",
    "plt.title('Model Performance Comparison(5-Fold Cross-Validation ± Standard Deviation)', fontsize=14, fontweight='bold')\n",
    "plt.xlim(0, 1)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (mean, std) in enumerate(zip(mean_scores, std_scores)):\n",
    "    plt.text(mean + 0.01, i, f'{mean:.3f} ± {std:.3f}',\n",
    "             va='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show individual fold scores for the best model\n",
    "print(f' Detailed CV Scores for {best_model_name}:')\n",
    "best_scores = cv_results[best_model_name]['all_scores']\n",
    "for fold, score in enumerate(best_scores, 1):\n",
    "    print(f'  Fold {fold}: {score:.4f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "44ec079e-9a5b-4b3c-8b67-054d44c2629a",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d2e3d70-1302-41b0-8df4-fdbb79fd0ddf",
   "metadata": {},
   "source": [
    "# find best params for logistic regression\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(solver='liblinear', max_iter=500))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__C': [0.1, 1, 5, 10, 50],\n",
    "    'clf__penalty': ['l1', 'l2'],\n",
    "    'clf__class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "grid_log = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='recall',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_log.fit(X_train_imbalanced, y_train_imbalanced)\n",
    "\n",
    "print('Best params:', grid_log.best_params_)\n",
    "print('Best score:', grid_log.best_score_)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "67c7547a-318e-4755-9db7-07b643d0b50b",
   "metadata": {},
   "source": [
    "# find best params for svm\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', SVC(probability=True))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__kernel': ['rbf', 'linear'],\n",
    "    'clf__C': [0.1, 1, 5, 10, 50],\n",
    "    'clf__gamma': ['scale', 'auto']\n",
    "}\n",
    "grid_log = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='recall',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_log.fit(X_train_imbalanced, y_train_imbalanced)\n",
    "\n",
    "print('Best params:', grid_log.best_params_)\n",
    "print('Best score:', grid_log.best_score_)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "17e51247-466d-4106-abc8-4682bca03154",
   "metadata": {},
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    classification_report, confusion_matrix, RocCurveDisplay\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b3a3d8d2-2e2a-464e-ad71-ae8b1d7c3638",
   "metadata": {},
   "source": [
    "log_reg_best = Pipeline([\n",
    "    ('smote', SMOTE()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(\n",
    "        C=0.1,\n",
    "        penalty='l2',\n",
    "        class_weight='balanced',\n",
    "        solver='liblinear',\n",
    "        max_iter=500,\n",
    "        random_state=13\n",
    "    ))\n",
    "])\n",
    "\n",
    "log_reg_best.fit(X_train_imbalanced, y_train_imbalanced)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "599652d2-066c-4942-a16d-3b1cebc77a95",
   "metadata": {},
   "source": [
    "y_pred_lr = log_reg_best.predict(X_test)\n",
    "y_prob_lr = log_reg_best.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "print('\\n=== Logistic Regression Evaluation ===')\n",
    "print(f'Accuracy:  {accuracy_score(y_test, y_pred_lr):.4f}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_lr):.4f}')\n",
    "print(f'Recall:    {recall_score(y_test, y_pred_lr):.4f}')\n",
    "print(f'F1 Score:  {f1_score(y_test, y_pred_lr):.4f}')\n",
    "print(f'ROC AUC:   {roc_auc_score(y_test, y_prob_lr):.4f}')\n",
    "\n",
    "print(' Detailed Classification Report:')\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['No Disease', 'Disease']))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_lr))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d80ae32-7f8b-48d1-bd1e-abf58c0e469b",
   "metadata": {},
   "source": [
    "# probability tweaking for log_reg\n",
    "y_pred_lr = log_reg_best.predict(X_test)\n",
    "y_prob_lr = log_reg_best.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "threshold = 0.67\n",
    "y_pred_lr_adj = (y_prob_lr >= threshold).astype(int)\n",
    "\n",
    "print('\\n=== Logistic Regression Evaluation ===')\n",
    "print(f'Accuracy:  {accuracy_score(y_test, y_pred_lr_adj ):.4f}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_lr_adj ):.4f}')\n",
    "print(f'Recall:    {recall_score(y_test, y_pred_lr_adj ):.4f}')\n",
    "print(f'F1 Score:  {f1_score(y_test, y_pred_lr_adj ):.4f}')\n",
    "print(f'ROC AUC:   {roc_auc_score(y_test, y_pred_lr_adj ):.4f}')\n",
    "\n",
    "print(' Detailed Classification Report:')\n",
    "print(classification_report(y_test, y_pred_lr_adj, target_names=['No Disease', 'Disease']))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_lr_adj))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0902b291-8001-4391-a79e-a5e251604d64",
   "metadata": {},
   "source": [
    "svm_best = Pipeline([\n",
    "    ('smote', SMOTE()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', SVC(\n",
    "        C=50,\n",
    "        kernel='linear',\n",
    "        probability=True,\n",
    "        random_state=13\n",
    "    ))\n",
    "])\n",
    "\n",
    "svm_best.fit(X_train_imbalanced, y_train_imbalanced)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "61ae9fe2-fb3a-4c82-9fd0-31f6902645fa",
   "metadata": {},
   "source": [
    "y_pred_svm = svm_best.predict(X_test)\n",
    "y_prob_svm = svm_best.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('\\n=== SVM Evaluation ===')\n",
    "print(f'Accuracy:  {accuracy_score(y_test, y_pred_svm):.4f}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_svm):.4f}')\n",
    "print(f'Recall:    {recall_score(y_test, y_pred_svm):.4f}')\n",
    "print(f'F1 Score:  {f1_score(y_test, y_pred_svm):.4f}')\n",
    "print(f'ROC AUC:   {roc_auc_score(y_test, y_pred_svm):.4f}')\n",
    "\n",
    "print(' Detailed Classification Report:')\n",
    "print(classification_report(y_test, y_pred_svm, target_names=['No Disease', 'Disease']))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e1699db0-202e-4a1f-a55e-12713475b356",
   "metadata": {},
   "source": [
    "# probability tweaking for svm\n",
    "y_pred_svm = svm_best.predict(X_test)\n",
    "y_prob_svm = svm_best.predict_proba(X_test)[:,1]\n",
    "\n",
    "threshold = 0.65\n",
    "y_pred_svm_adj = (y_prob_svm >= threshold).astype(int)\n",
    "\n",
    "print('\\n=== SVM Evaluation ===')\n",
    "print(f'Accuracy:  {accuracy_score(y_test, y_pred_svm_adj):.4f}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_svm_adj):.4f}')\n",
    "print(f'Recall:    {recall_score(y_test, y_pred_svm_adj):.4f}')\n",
    "print(f'F1 Score:  {f1_score(y_test, y_pred_svm_adj):.4f}')\n",
    "print(f'ROC AUC:   {roc_auc_score(y_test, y_pred_svm_adj):.4f}')\n",
    "\n",
    "print(' Detailed Classification Report:')\n",
    "print(classification_report(y_test, y_pred_svm_adj, target_names=['No Disease', 'Disease']))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred_svm_adj))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2a551dec-30de-41ab-8c4e-12635ce009d5",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    "    classification_report\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4d677654-bfb5-460d-a0ca-8f480977f94d",
   "metadata": {},
   "source": [
    "def evaluate_model(name, model, X_test, y_test, threshold=0.5):\n",
    "    print(f'\\n=== {name} Evaluation ===')\n",
    "\n",
    "    # Probability (positive class)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # ROC-AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    print(f'ROC-AUC: {roc_auc:.4f}')\n",
    "\n",
    "    # Thresholding\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'{name} — Confusion Matrix (threshold={threshold})')\n",
    "    plt.show()\n",
    "\n",
    "    # Metrics\n",
    "    print('\\nClassification Report:')\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "    # Precision–Recall & PR-AUC\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, label=f'PR-AUC = {pr_auc:.4f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'{name} — Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return {\n",
    "        'roc_auc': roc_auc,\n",
    "        'pr_auc': pr_auc,\n",
    "        'confusion_matrix': cm\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "142b7268-dd8d-46fe-8aa7-6bb81a8b00c8",
   "metadata": {},
   "source": [
    "results_log = evaluate_model(\n",
    "    name='Logistic Regression',\n",
    "    model=log_reg_best,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    threshold=0.67\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "216d34d3-4048-4ee5-9d35-8883aa054576",
   "metadata": {},
   "source": [
    "results_log = evaluate_model(\n",
    "    name='SVM',\n",
    "    model=svm_best,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    threshold=0.65\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "92490694-f872-42f8-a742-056c60f4eca1",
   "metadata": {},
   "source": [
    "import pickle\n",
    "\n",
    "model_path = '../trained_models/stroke-svm_model.pkl'\n",
    "\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(svm_best, f)\n",
    "print('Models saved successfully.')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b170ffd5-a8ad-486d-98a9-c6181eec96ee",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
